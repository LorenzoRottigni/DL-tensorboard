{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('cancer_classification.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('benign_0__mal_1', axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['benign_0__mal_1'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.25,random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/lorenzorottigni/Documents/DL-tensorboard'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2023-06-06--1625'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "datetime.now().strftime(\"%Y-%m-%d--%H%M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = 'logs/fit'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-06 16:25:54.457371: I tensorflow/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2023-06-06 16:25:54.457392: I tensorflow/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2023-06-06 16:25:54.457870: I tensorflow/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n"
     ]
    }
   ],
   "source": [
    "board = TensorBoard(\n",
    "    log_dir=log_dir,\n",
    "    histogram_freq=1,\n",
    "    write_graph=True,\n",
    "    write_images=True,\n",
    "    update_freq='epoch',\n",
    "    profile_batch=2,\n",
    "    embeddings_freq=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(units=30, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(units=15, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/600\n",
      " 1/14 [=>............................] - ETA: 11s - loss: 0.7348"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-06 16:25:55.504034: I tensorflow/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2023-06-06 16:25:55.504052: I tensorflow/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2023-06-06 16:25:55.529134: I tensorflow/tsl/profiler/lib/profiler_session.cc:70] Profiler session collecting data.\n",
      "2023-06-06 16:25:55.530042: I tensorflow/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 1s 24ms/step - loss: 0.7210 - val_loss: 0.6573\n",
      "Epoch 2/600\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.6814 - val_loss: 0.6334\n",
      "Epoch 3/600\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.6671 - val_loss: 0.6116\n",
      "Epoch 4/600\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.6274 - val_loss: 0.5873\n",
      "Epoch 5/600\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.6125 - val_loss: 0.5629\n",
      "Epoch 6/600\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.6112 - val_loss: 0.5418\n",
      "Epoch 7/600\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.5723 - val_loss: 0.5151\n",
      "Epoch 8/600\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.5460 - val_loss: 0.4824\n",
      "Epoch 9/600\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.5188 - val_loss: 0.4527\n",
      "Epoch 10/600\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.5079 - val_loss: 0.4202\n",
      "Epoch 11/600\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.4914 - val_loss: 0.3987\n",
      "Epoch 12/600\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.4796 - val_loss: 0.3831\n",
      "Epoch 13/600\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.4560 - val_loss: 0.3643\n",
      "Epoch 14/600\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.4102 - val_loss: 0.3350\n",
      "Epoch 15/600\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.4189 - val_loss: 0.3106\n",
      "Epoch 16/600\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.4024 - val_loss: 0.2964\n",
      "Epoch 17/600\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.4127 - val_loss: 0.2811\n",
      "Epoch 18/600\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.3872 - val_loss: 0.2677\n",
      "Epoch 19/600\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.3661 - val_loss: 0.2619\n",
      "Epoch 20/600\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.3460 - val_loss: 0.2474\n",
      "Epoch 21/600\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.3332 - val_loss: 0.2354\n",
      "Epoch 22/600\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.3361 - val_loss: 0.2236\n",
      "Epoch 23/600\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.3077 - val_loss: 0.2129\n",
      "Epoch 24/600\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.3116 - val_loss: 0.2053\n",
      "Epoch 25/600\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.3097 - val_loss: 0.1935\n",
      "Epoch 26/600\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.2914 - val_loss: 0.1965\n",
      "Epoch 27/600\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.2854 - val_loss: 0.1889\n",
      "Epoch 28/600\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.2415 - val_loss: 0.1800\n",
      "Epoch 29/600\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.2710 - val_loss: 0.1691\n",
      "Epoch 30/600\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.2590 - val_loss: 0.1660\n",
      "Epoch 31/600\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.2593 - val_loss: 0.1719\n",
      "Epoch 32/600\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.2315 - val_loss: 0.1520\n",
      "Epoch 33/600\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.2490 - val_loss: 0.1523\n",
      "Epoch 34/600\n",
      "14/14 [==============================] - 0s 15ms/step - loss: 0.2377 - val_loss: 0.1495\n",
      "Epoch 35/600\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.2192 - val_loss: 0.1471\n",
      "Epoch 36/600\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.2572 - val_loss: 0.1559\n",
      "Epoch 37/600\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.2269 - val_loss: 0.1482\n",
      "Epoch 38/600\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.2164 - val_loss: 0.1395\n",
      "Epoch 39/600\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.2134 - val_loss: 0.1356\n",
      "Epoch 40/600\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.2034 - val_loss: 0.1332\n",
      "Epoch 41/600\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.2109 - val_loss: 0.1394\n",
      "Epoch 42/600\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1836 - val_loss: 0.1232\n",
      "Epoch 43/600\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1897 - val_loss: 0.1245\n",
      "Epoch 44/600\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.2302 - val_loss: 0.1250\n",
      "Epoch 45/600\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1806 - val_loss: 0.1228\n",
      "Epoch 46/600\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.1749 - val_loss: 0.1175\n",
      "Epoch 47/600\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.2009 - val_loss: 0.1227\n",
      "Epoch 48/600\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.1973 - val_loss: 0.1171\n",
      "Epoch 49/600\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.1849 - val_loss: 0.1129\n",
      "Epoch 50/600\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.1693 - val_loss: 0.1115\n",
      "Epoch 51/600\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.2070 - val_loss: 0.1108\n",
      "Epoch 52/600\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.1796 - val_loss: 0.1077\n",
      "Epoch 53/600\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.1801 - val_loss: 0.1126\n",
      "Epoch 54/600\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.1568 - val_loss: 0.1112\n",
      "Epoch 55/600\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1472 - val_loss: 0.1059\n",
      "Epoch 56/600\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.1780 - val_loss: 0.1156\n",
      "Epoch 57/600\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.1517 - val_loss: 0.1235\n",
      "Epoch 58/600\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.1698 - val_loss: 0.0986\n",
      "Epoch 59/600\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1850 - val_loss: 0.1009\n",
      "Epoch 60/600\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.1630 - val_loss: 0.1080\n",
      "Epoch 61/600\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1573 - val_loss: 0.0987\n",
      "Epoch 62/600\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.1620 - val_loss: 0.1097\n",
      "Epoch 63/600\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.1663 - val_loss: 0.1066\n",
      "Epoch 64/600\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1380 - val_loss: 0.1003\n",
      "Epoch 65/600\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.1490 - val_loss: 0.1014\n",
      "Epoch 66/600\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.1213 - val_loss: 0.0959\n",
      "Epoch 67/600\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.1470 - val_loss: 0.0926\n",
      "Epoch 68/600\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1515 - val_loss: 0.1065\n",
      "Epoch 69/600\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.1391 - val_loss: 0.0984\n",
      "Epoch 70/600\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.1542 - val_loss: 0.0904\n",
      "Epoch 71/600\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.1452 - val_loss: 0.0923\n",
      "Epoch 72/600\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.1399 - val_loss: 0.1010\n",
      "Epoch 73/600\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.1507 - val_loss: 0.0979\n",
      "Epoch 74/600\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1331 - val_loss: 0.1018\n",
      "Epoch 75/600\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.1284 - val_loss: 0.0943\n",
      "Epoch 76/600\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.1359 - val_loss: 0.1000\n",
      "Epoch 77/600\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1282 - val_loss: 0.0930\n",
      "Epoch 78/600\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.1382 - val_loss: 0.1019\n",
      "Epoch 79/600\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.1258 - val_loss: 0.0948\n",
      "Epoch 80/600\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.1286 - val_loss: 0.0956\n",
      "Epoch 81/600\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.1346 - val_loss: 0.1154\n",
      "Epoch 82/600\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.1215 - val_loss: 0.0932\n",
      "Epoch 83/600\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1331 - val_loss: 0.0901\n",
      "Epoch 84/600\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.1255 - val_loss: 0.0905\n",
      "Epoch 85/600\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.1377 - val_loss: 0.0951\n",
      "Epoch 86/600\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.1181 - val_loss: 0.1074\n",
      "Epoch 87/600\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.1329 - val_loss: 0.0956\n",
      "Epoch 88/600\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.1370 - val_loss: 0.0903\n",
      "Epoch 89/600\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1230 - val_loss: 0.1095\n",
      "Epoch 90/600\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.1341 - val_loss: 0.0927\n",
      "Epoch 91/600\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.1243 - val_loss: 0.0963\n",
      "Epoch 92/600\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1557 - val_loss: 0.0944\n",
      "Epoch 93/600\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.1141 - val_loss: 0.0975\n",
      "Epoch 94/600\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.0939 - val_loss: 0.1017\n",
      "Epoch 95/600\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.1218 - val_loss: 0.0871\n",
      "Epoch 96/600\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.0951 - val_loss: 0.1073\n",
      "Epoch 97/600\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.1348 - val_loss: 0.0886\n",
      "Epoch 98/600\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.1121 - val_loss: 0.0888\n",
      "Epoch 99/600\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.1102 - val_loss: 0.0897\n",
      "Epoch 100/600\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1285 - val_loss: 0.0997\n",
      "Epoch 101/600\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.1227 - val_loss: 0.1041\n",
      "Epoch 102/600\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.1235 - val_loss: 0.0960\n",
      "Epoch 103/600\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1167 - val_loss: 0.0900\n",
      "Epoch 104/600\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.1191 - val_loss: 0.0939\n",
      "Epoch 105/600\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1064 - val_loss: 0.0967\n",
      "Epoch 106/600\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.0970 - val_loss: 0.1005\n",
      "Epoch 107/600\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1060 - val_loss: 0.1106\n",
      "Epoch 108/600\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.1104 - val_loss: 0.0927\n",
      "Epoch 109/600\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.0933 - val_loss: 0.0880\n",
      "Epoch 110/600\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.1303 - val_loss: 0.1066\n",
      "Epoch 111/600\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1027 - val_loss: 0.0848\n",
      "Epoch 112/600\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.1074 - val_loss: 0.0996\n",
      "Epoch 113/600\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.1247 - val_loss: 0.1082\n",
      "Epoch 114/600\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.1106 - val_loss: 0.0851\n",
      "Epoch 115/600\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.1044 - val_loss: 0.1027\n",
      "Epoch 116/600\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.0999 - val_loss: 0.1206\n",
      "Epoch 117/600\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1178 - val_loss: 0.0979\n",
      "Epoch 118/600\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.0935 - val_loss: 0.0974\n",
      "Epoch 119/600\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1078 - val_loss: 0.0863\n",
      "Epoch 120/600\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.1178 - val_loss: 0.0962\n",
      "Epoch 121/600\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.1026 - val_loss: 0.1004\n",
      "Epoch 122/600\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.1167 - val_loss: 0.0904\n",
      "Epoch 123/600\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.1016 - val_loss: 0.1007\n",
      "Epoch 124/600\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.0881 - val_loss: 0.0953\n",
      "Epoch 125/600\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.1047 - val_loss: 0.0953\n",
      "Epoch 126/600\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.1124 - val_loss: 0.1155\n",
      "Epoch 127/600\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.1032 - val_loss: 0.0981\n",
      "Epoch 128/600\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.0994 - val_loss: 0.1091\n",
      "Epoch 129/600\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.0923 - val_loss: 0.0998\n",
      "Epoch 130/600\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.0919 - val_loss: 0.1018\n",
      "Epoch 131/600\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1139 - val_loss: 0.0847\n",
      "Epoch 132/600\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1276 - val_loss: 0.0961\n",
      "Epoch 133/600\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1010 - val_loss: 0.1112\n",
      "Epoch 134/600\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.1185 - val_loss: 0.1040\n",
      "Epoch 135/600\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.0986 - val_loss: 0.0888\n",
      "Epoch 136/600\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.1069 - val_loss: 0.0938\n",
      "Epoch 137/600\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.1086 - val_loss: 0.1207\n",
      "Epoch 138/600\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.0976 - val_loss: 0.1020\n",
      "Epoch 139/600\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.0987 - val_loss: 0.0861\n",
      "Epoch 140/600\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.0820 - val_loss: 0.1065\n",
      "Epoch 141/600\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1052 - val_loss: 0.1036\n",
      "Epoch 142/600\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.0814 - val_loss: 0.1006\n",
      "Epoch 143/600\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.0755 - val_loss: 0.0911\n",
      "Epoch 144/600\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.0895 - val_loss: 0.1010\n",
      "Epoch 145/600\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1100 - val_loss: 0.0980\n",
      "Epoch 146/600\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1013 - val_loss: 0.0985\n",
      "Epoch 147/600\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.0836 - val_loss: 0.0879\n",
      "Epoch 148/600\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0828 - val_loss: 0.0955\n",
      "Epoch 149/600\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.0781 - val_loss: 0.1015\n",
      "Epoch 150/600\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.0849 - val_loss: 0.0921\n",
      "Epoch 151/600\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.0848 - val_loss: 0.1046\n",
      "Epoch 152/600\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.0889 - val_loss: 0.1028\n",
      "Epoch 153/600\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.0975 - val_loss: 0.0926\n",
      "Epoch 154/600\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.0853 - val_loss: 0.0945\n",
      "Epoch 155/600\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.0993 - val_loss: 0.1125\n",
      "Epoch 156/600\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1112 - val_loss: 0.1128\n",
      "Epoch 156: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1537000d0>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    x=X_train,\n",
    "    y=y_train,\n",
    "    epochs=600,\n",
    "    validation_data=(X_test, y_test),\n",
    "    verbose=1,\n",
    "    callbacks=[early_stop, board]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logs/fit\n"
     ]
    }
   ],
   "source": [
    "print(log_dir)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorboard will tipically run on port 6006 and it's possible to start it like this:\n",
    "- conda activate => activate venv\n",
    "- move into project directory where the logs are stored\n",
    "- tensorboard --logdir <log_directory> --host localhost --port 6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
